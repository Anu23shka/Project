{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "809b5fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import re\n",
    "import string\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe8c2461",
   "metadata": {},
   "outputs": [],
   "source": [
    "review = pd.read_csv(\"df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fce5eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N    20752\n",
       "Y     6206\n",
       "Name: flagged, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#review.shape\n",
    "review['flagged'].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "610fdc9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76.97900437717932\n",
      "23.020995622820685\n"
     ]
    }
   ],
   "source": [
    "Not_Fake_Percentage = (20752/(20752+6206))*100\n",
    "Fake_Percentage = (6206/(20752+6206))*100\n",
    "print(Not_Fake_Percentage)\n",
    "print(Fake_Percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12959481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                      reviewID              reviewerID            restaurantID  \\\n",
       "0      GtwU21YOQn-wf4vWRUIx6w  bNYesZ944s6IJVowOnB0iA  pbEiXam9YJL3neCYHGwLUA   \n",
       "1                     0LpVTc3  TRKxLC3y-ZvP45e5iilMtw  pbEiXam9YJL3neCYHGwLUA   \n",
       "2               tljtLzf68Fkwf  0EMm8umAqXZzyhxNpL4M9g  pbEiXam9YJL3neCYHGwLUA   \n",
       "3                         iSN  DlwexC7z88ymAzu45skODw  pbEiXam9YJL3neCYHGwLUA   \n",
       "4                      Jmwrh7  kW2dk1CWihmh3g7k9N2G8A  pbEiXam9YJL3neCYHGwLUA   \n",
       "...                       ...                     ...                     ...   \n",
       "26953              PZu8sDx2T2  tivh8lr6pzBDNfrJLYWh_g  v9qEDxi3t-P0CmGWAkkGvw   \n",
       "26954               S-zbPPGoB  jKs4FQgkV0wSX8BG2_dgTg  RRflazDtBkqqpvEz2hbV2w   \n",
       "26955    roKqXYooTy49OMAIJJjf  vX6aOMQ3HWCbwZVfCkCauw  zI0E_yruu58ea-xq9aHi-w   \n",
       "26956                FefmFaWa  vX6aOMQ3HWCbwZVfCkCauw  6XVXM78gBuU3gpq2hTOgJA   \n",
       "26957    x8knvE6V8MkwT90wCV0f  OZTkqoi8_luhrL-mMj7O8A  Lr4tZOsttQT-BgFtUkUTaQ   \n",
       "\n",
       "             date  rating  reviewUsefulCount  \\\n",
       "0       9/22/2012       5                  0   \n",
       "1       9/22/2012       5                  0   \n",
       "2       9/19/2012       3                  2   \n",
       "3        9/6/2012       3                  8   \n",
       "4        9/9/2012       5                  1   \n",
       "...           ...     ...                ...   \n",
       "26953   3/17/2010       4                  0   \n",
       "26954   4/14/2011       5                  0   \n",
       "26955   9/23/2007       3                  0   \n",
       "26956  11/18/2011       3                  0   \n",
       "26957   5/18/2012       4                  0   \n",
       "\n",
       "                                           reviewContent flagged  \\\n",
       "0      unlike next we d eaten previous night dish com...       N   \n",
       "1      probably one best meals i ve ever it s perform...       N   \n",
       "2      service impeccable experience presentation coo...       N   \n",
       "3      the problem places like this given exhorbitant...       N   \n",
       "4      i idea write review dining alinea brings whole...       N   \n",
       "...                                                  ...     ...   \n",
       "26953  it s taco bell higher prices taco bell what st...       N   \n",
       "26954  yellow rose favorite mine i d go every day i c...       N   \n",
       "26955  not bad we ate odd wicker seats inviting we at...       N   \n",
       "26956  we surprised eagerly roped pop trivia game upo...       N   \n",
       "26957  a gorgeous shy young teen asked owner could si...       N   \n",
       "\n",
       "                            name                    location  ... coolCount  \\\n",
       "0                       Scott E.                Glengary, WV  ...         5   \n",
       "1                       Jerry K.  Palos Verdes Peninsula, CA  ...         0   \n",
       "2                    Patricia M.                 Chicago, IL  ...         0   \n",
       "3                       Terry N.                San Jose, CA  ...         8   \n",
       "4      Shradha Vegetarianista A.                 Chicago, IL  ...       679   \n",
       "...                          ...                         ...  ...       ...   \n",
       "26953                 Kristen F.                 Chicago, IL  ...        56   \n",
       "26954                  Yvonne F.                          IL  ...         2   \n",
       "26955                 Saverio T.                 Chicago, IL  ...         9   \n",
       "26956                 Saverio T.                 Chicago, IL  ...         9   \n",
       "26957                   J. C. R.                 Chicago, IL  ...         2   \n",
       "\n",
       "       funnyCount  complimentCount  tipCount  fanCount  restaurantRating  \\\n",
       "0               5                2         0         1               4.5   \n",
       "1               0                0         0         0               4.5   \n",
       "2               1                0         0         0               4.5   \n",
       "3               6                6        11         0               4.5   \n",
       "4             417              283        22        70               4.5   \n",
       "...           ...              ...       ...       ...               ...   \n",
       "26953          17               24         0         3               4.0   \n",
       "26954           0                1         0         1               4.0   \n",
       "26955          10                7         1         1               4.0   \n",
       "26956          10                7         1         1               4.0   \n",
       "26957           4                6        14         0               4.5   \n",
       "\n",
       "            mnr   rl     rd  Maximum Content Similarity  \n",
       "0      0.083333  497  0.125                    0.123653  \n",
       "1      0.083333   41  0.125                    0.000000  \n",
       "2      0.083333   27  0.375                    0.000000  \n",
       "3      0.083333  244  0.375                    0.000000  \n",
       "4      0.083333   97  0.125                    0.760866  \n",
       "...         ...  ...    ...                         ...  \n",
       "26953  0.083333   48  0.000                    0.111133  \n",
       "26954  0.083333   63  0.250                    0.139705  \n",
       "26955  0.083333   27  0.250                    0.050463  \n",
       "26956  0.083333   42  0.250                    0.050463  \n",
       "26957  0.083333   20  0.125                    0.000000  \n",
       "\n",
       "[26958 rows x 25 columns]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5286301e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomly shuffling the dataframe\n",
    "review = review.sample(frac = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0a6893c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#review.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1af883e",
   "metadata": {},
   "outputs": [],
   "source": [
    "review.reset_index(inplace = True)\n",
    "review.drop([\"index\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d970e9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#review.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94cca2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#review.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d8d15ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a function to convert the text in lowercase, remove the extra space, special chr.\n",
    "def wordopt(reviewContent):\n",
    "    reviewContent = re.sub('\\[.*?\\]', '', str(reviewContent))\n",
    "    reviewContent = re.sub(\"\\\\W\",\" \",reviewContent) \n",
    "    reviewContent = re.sub('https?://\\S+|www\\.\\S+', '',reviewContent )\n",
    "    reviewContent = re.sub('<.*?>+', '', reviewContent)\n",
    "    reviewContent= re.sub('[%s]' % re.escape(string.punctuation), '',reviewContent )\n",
    "    reviewContent = re.sub('\\n', '',reviewContent )\n",
    "    reviewContent = re.sub('\\w*\\d\\w*', '', reviewContent)    \n",
    "    return reviewContent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d8e8b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "review[\"reviewContent\"] = review[\"reviewContent\"].apply(wordopt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14f27fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "    # Maximum Number of Reviews per day per reviewer\n",
    "    mnr_df1 = df[['reviewerID', 'date']].copy()\n",
    "    mnr_df2 = mnr_df1.groupby(by=['date', 'reviewerID']).size().reset_index(name='mnr')\n",
    "    mnr_df2['mnr'] = mnr_df2['mnr'] / mnr_df2['mnr'].max()\n",
    "    df = df.merge(mnr_df2, on=['reviewerID', 'date'], how='inner')\n",
    "\n",
    "    # Review Length\n",
    "    df['rl'] = df['reviewContent'].apply(lambda x: len(x.split()))\n",
    "\n",
    "    # Review Deviation\n",
    "    df['rd'] = abs(df['rating'] - df['restaurantRating']) / 4\n",
    "\n",
    "    # Maximum cosine similarity\n",
    "    review_data = df\n",
    "\n",
    "    res = OrderedDict()\n",
    "\n",
    "    # Iterate over data and create groups of reviewers\n",
    "    for row in review_data.iterrows():\n",
    "        if row[1].reviewerID in res:\n",
    "            res[row[1].reviewerID].append(row[1].reviewContent)\n",
    "        else:\n",
    "            res[row[1].reviewerID] = [row[1].reviewContent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a144da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def under_sampling(df):\n",
    "    print(\"Under-Sampling Data\")\n",
    "    # Count of Reviews\n",
    "    # print(\"Authentic\", len(df[(df['flagged'] == 'N')]))\n",
    "    # print(\"Fake\", len(df[(df['flagged'] == 'Y')]))\n",
    "\n",
    "    sample_size = len(df[(df['flagged'] == 'Y')])\n",
    "\n",
    "    authentic_reviews_df = df[df['flagged'] == 'N']\n",
    "    fake_reviews_df = df[df['flagged'] == 'Y']\n",
    "\n",
    "    authentic_reviews_us_df = authentic_reviews_df.sample(sample_size)\n",
    "    under_sampled_df = pd.concat([authentic_reviews_us_df, fake_reviews_df], axis=0)\n",
    "\n",
    "    # print(\"Under-Sampled Fake\", len(under_sampled_df[(under_sampled_df['flagged'] == 'Y')]))\n",
    "    # print(\"Under-Sampled Authentic\", len(under_sampled_df[(under_sampled_df['flagged'] == 'N')]))\n",
    "\n",
    "    # Graph of Data Distribution\n",
    "    # fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    # sns.countplot(x='flagged', data=under_sampled_df)\n",
    "    # plt.title(\"Count of Reviews\")\n",
    "    # plt.show()\n",
    "    print(\"Under-Sampling Complete\")\n",
    "    return under_sampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e09e6865",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semi_supervised_learning(df, model, algorithm, threshold=0.8, iterations=40):\n",
    "    df = df.copy()\n",
    "    print(\"Training \"+algorithm+\" Model\")\n",
    "    labels = df['flagged']\n",
    "\n",
    "    df.drop(['reviewID', 'reviewerID', 'restaurantID', 'date', 'name', 'location', 'yelpJoinDate', 'flagged',\n",
    "             'reviewContent', 'restaurantRating'], axis=1, inplace=True)\n",
    "\n",
    "    train_data, test_data, train_label, test_label = train_test_split(df, labels, test_size=0.25, random_state=42)\n",
    "\n",
    "    test_data_copy = test_data.copy()\n",
    "    test_label_copy = test_label.copy()\n",
    "\n",
    "    all_labeled = False\n",
    "\n",
    "    current_iteration = 0\n",
    "\n",
    "    # param_grid = {\n",
    "    #     'n_estimators': [10, 500],\n",
    "    #     'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    #     'max_depth': [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14],\n",
    "    #     'criterion': ['gini', 'entropy']\n",
    "    # }\n",
    "    # grid_clf_acc = GridSearchCV(estimator=model, param_grid=param_grid, cv=5)\n",
    "    #\n",
    "    # grid_clf_acc.fit(train_data, train_label)\n",
    "\n",
    "    pbar = tqdm(total=iterations)\n",
    "\n",
    "    while not all_labeled and (current_iteration < iterations):\n",
    "        # print(\"Before train data length : \", len(train_data))\n",
    "        # print(\"Before test data length : \", len(test_data))\n",
    "        current_iteration += 1\n",
    "        model.fit(train_data, train_label)\n",
    "\n",
    "        probabilities = model.predict_proba(test_data)\n",
    "        pseudo_labels = model.predict(test_data)\n",
    "\n",
    "        indices = np.argwhere(probabilities > threshold)\n",
    "        # print(\"rows above threshold : \", len(indices))\n",
    "        for item in indices:\n",
    "            train_data.loc[test_data.index[item[0]]] = test_data.iloc[item[0]]\n",
    "            train_label.loc[test_data.index[item[0]]] = pseudo_labels[item[0]]\n",
    "        test_data.drop(test_data.index[indices[:, 0]], inplace=True)\n",
    "        test_label.drop(test_label.index[indices[:, 0]], inplace=True)\n",
    "        # print(\"After train data length : \", len(train_data))\n",
    "        # print(\"After test data length : \", len(test_data))\n",
    "        print(\"--\" * 20)\n",
    "\n",
    "        if len(test_data) == 0:\n",
    "            print(\"Exiting loop\")\n",
    "            all_labeled = True\n",
    "        pbar.update(1)\n",
    "    pbar.close()\n",
    "    predicted_labels = model.predict(test_data_copy)\n",
    "\n",
    "    # print('Best Params : ', grid_clf_acc.best_params_)\n",
    "    print(algorithm + ' Model Results')\n",
    "    print('--' * 20)\n",
    "    print('Accuracy Score : ' + str(accuracy_score(test_label_copy, predicted_labels)))\n",
    "    print('Precision Score : ' + str(precision_score(test_label_copy, predicted_labels, pos_label=\"Y\")))\n",
    "    print('Recall Score : ' + str(recall_score(test_label_copy, predicted_labels, pos_label=\"Y\")))\n",
    "    print('F1 Score : ' + str(f1_score(test_label_copy, predicted_labels, pos_label=\"Y\")))\n",
    "    print('Confusion Matrix : \\n' + str(confusion_matrix(test_label_copy, predicted_labels)))\n",
    "    plot_confusion_matrix(test_label_copy, predicted_labels, classes=['N', 'Y'],\n",
    "                          title=algorithm + ' Confusion Matrix').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97b5634f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes, title=None, cmap=plt.cm.Blues):\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           xticklabels=classes,\n",
    "           yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a17d2fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining dependent and independent variable as x and y\n",
    "x = review[\"reviewContent\"]\n",
    "y = review[\"flagged\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f5dfbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the dataset into training set and testing set.\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23da3417",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert text to vectors\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorization = TfidfVectorizer()\n",
    "xv_train = vectorization.fit_transform(x_train)\n",
    "xv_test = vectorization.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aaca2b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dcd3676c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR = LogisticRegression()\n",
    "LR.fit(xv_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16c1b816",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lr=LR.predict(xv_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "921e0887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N    20752\n",
       "Y     6206\n",
       "Name: flagged, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review['flagged'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f08f170e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7864985163204747"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR.score(xv_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ee16ba6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e7c74b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DT = DecisionTreeClassifier()\n",
    "DT.fit(xv_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7898bb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dt = DT.predict(xv_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7ad8ec84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6899109792284867"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DT.score(xv_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "52825d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.80      0.80      0.80      5202\n",
      "           Y       0.32      0.31      0.31      1538\n",
      "\n",
      "    accuracy                           0.69      6740\n",
      "   macro avg       0.56      0.56      0.56      6740\n",
      "weighted avg       0.69      0.69      0.69      6740\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "67a083a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aec236c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(random_state=0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GBC = GradientBoostingClassifier(random_state=0)\n",
    "GBC.fit(xv_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f9b8284f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_gbc = GBC.predict(xv_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "146df561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7793768545994065"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GBC.score(xv_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a4d87f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a053f345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFC = RandomForestClassifier(random_state=0)\n",
    "RFC.fit(xv_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5372eaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rfc = RFC.predict(xv_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dc54dd34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7698813056379822"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFC.score(xv_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "301378de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.77      0.99      0.87      5202\n",
      "           Y       0.42      0.02      0.04      1538\n",
      "\n",
      "    accuracy                           0.77      6740\n",
      "   macro avg       0.59      0.51      0.45      6740\n",
      "weighted avg       0.69      0.77      0.68      6740\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred_rfc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9dc83f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_lable(n):\n",
    "    if n == 0:\n",
    "        return \"Not A Fake Review\"\n",
    "    elif n == 1:\n",
    "        return \"Fake Review\"\n",
    "    \n",
    "def manual_testing(review):\n",
    "    testing_review = {\"reviewContent\":[review]}\n",
    "    new_def_test= pd.DataFrame(testing_review)\n",
    "    new_def_test[\"reviewContent\"] = new_def_test[\"reviewContent\"].apply(wordopt) \n",
    "    new_x_test = new_def_test[\"reviewContent\"]\n",
    "    new_xv_test = vectorization.transform(new_x_test)\n",
    "    pred_LR = LR.predict(new_xv_test)\n",
    "    pred_DT = DT.predict(new_xv_test)\n",
    "    pred_GBC = GBC.predict(new_xv_test)\n",
    "    pred_RFC = RFC.predict(new_xv_test)\n",
    "\n",
    "    return print(\"\\n\\nLR Prediction: {} \\nDT Prediction: {} \\nGBC Prediction: {} \\nRFC Prediction: {}\".format(output_lable(pred_LR[0]), \n",
    "                                                                                                              output_lable(pred_DT[0]), \n",
    "                                                                                                              output_lable(pred_GBC[0]), \n",
    "                                                                                                              output_lable(pred_RFC[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e639aa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "review = str(input())\n",
    "manual_testing(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745b786e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
